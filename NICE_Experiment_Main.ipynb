{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NICE_Experiment_Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://gist.github.com/rjin1/15c30d4b9cb3d24a3de4fb91298f4e18#file-nice_experiment_main-ipynb",
      "authorship_tag": "ABX9TyO3NVNd7QNEESOV0jptwKuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjin1/NICE_Experiments_Notebook/blob/main/NICE_Experiment_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3g5QTcDmojA"
      },
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.autograd as autograd\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from scipy.io import savemat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import argparse\n",
        "\n",
        "# np.set_printoptions(threshold=sys.maxsize)\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueaSx5hBnNTG"
      },
      "source": [
        "def Gen_Source(loc_filename = './drive/MyDrive/NICE_JupyterNotebook/DistributionParams/GumbelLocatParams.mat', loc_varname = 'locat_param', \n",
        "               scale_filename = './drive/MyDrive/NICE_JupyterNotebook/DistributionParams/GumbelScaleParams.mat', sacle_varname = 'scale_param', \n",
        "               N_sample = 7668, seed_gs = 1):\n",
        "  \n",
        "  loc = loadmat(loc_filename)[loc_varname].astype(np.float64)\n",
        "  scale = loadmat(scale_filename)[sacle_varname].astype(np.float64)\n",
        "\n",
        "  # Assume the loc and scale are in same format np.array in (N_source x 1)\n",
        "  N_source = loc.shape[0]\n",
        "  S = np.zeros((N_source, N_sample), np.float64)\n",
        "\n",
        "  # Control the RNG for repro\n",
        "  np.random.seed(seed_gs)\n",
        "  for i in range(N_source):\n",
        "    S[i,:] = np.random.gumbel(loc[i,0], scale[i,0], (1, N_sample))\n",
        "\n",
        "  return S"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8XJwVpjn7hf"
      },
      "source": [
        "def Gen_Mixture(S, ratio=1):\n",
        "  # Assume S is in np.array format in (N_souece x N_sample)\n",
        "  N_source_sample = S.shape\n",
        "  X = np.zeros((N_source_sample[0], N_source_sample[1]), np.float64)\n",
        "\n",
        "  for i in range(N_source_sample[1]):\n",
        "    for j in range(N_source_sample[0]):\n",
        "      X[j,i] = S[j,i] + ratio * (S[j,i] * (np.sum(S[:,i]) - S[j,i]) + np.sum(S[:,i] ** 2) - S[j,i] ** 2)\n",
        "\n",
        "  return X "
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgHOE7GqJPxf"
      },
      "source": [
        "def Train_Valid_Split(Data, N_train, N_valid, seed_tvs):\n",
        "  # Assume data in format np.array with (N_source x N_sample)\n",
        "  N_sample = Data.shape[1]\n",
        "  \n",
        "  np.random.seed(seed_tvs)\n",
        "  ind_all = np.random.permutation(N_sample)\n",
        "  ind_train = ind_all[:N_train]\n",
        "  ind_valid = ind_all[N_train:N_train+N_valid]\n",
        "\n",
        "  Data_train = Data[:,ind_train]\n",
        "  Data_valid = Data[:,ind_valid]\n",
        "\n",
        "  return Data_train, Data_valid"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2wBGM-mX34H"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # ----- parse training settings:\n",
        "    parser = argparse.ArgumentParser(description=\"Train a fresh NICE model and save.\")\n",
        "    # configuration settings:\n",
        "    parser.add_argument(\"--dataset\", default='fMRI', dest='dataset', choices=('tfd', 'cifar10', 'svhn', 'mnist'),\n",
        "                        help=\"Dataset to train the NICE model on.\")\n",
        "    parser.add_argument(\"--epochs\", dest='num_epochs', default=40000, type=int,\n",
        "                        help=\"Number of epochs to train on. [1500]\")\n",
        "    parser.add_argument(\"--batch_size\", dest=\"batch_size_train\", default=10, type=int,\n",
        "                        help=\"Number of training examples per batch. [16]\")\n",
        "    parser.add_argument(\"--Train_size\", dest=\"size_train\", default=5110, type=int,\n",
        "                        help=\"Number of training examples. [5110]\")\n",
        "    parser.add_argument(\"--Validation_size\", dest=\"size_valid\", default=2558, type=int,\n",
        "                        help=\"Number of validation examples. [2558]\")\n",
        "    parser.add_argument(\"--savedir\", dest='savedir',\n",
        "                        default=\"./drive/MyDrive/NICE_JupyterNotebook/Results/\",\n",
        "                        help=\"Where to save the results and trained models.\")\n",
        "    parser.add_argument(\"--initialization_path\", dest='init_filepath',\n",
        "                        default=\"./fMRI_data/\",\n",
        "                        help=\"Where to load the pretrained model parameters.\")\n",
        "\n",
        "    # validation and test:\n",
        "    parser.add_argument(\"--val_batch_size\", dest=\"batch_size_val\", default=2558, type=int,\n",
        "                        help=\"Number of validation examples per batch. [16]\")\n",
        "    parser.add_argument(\"--test_batch_size\", dest=\"batch_size_test\", default=7668, type=int,\n",
        "                        help=\"Number of test examples per batch. [16]\")\n",
        "    parser.add_argument(\"--early_stop_iteration\", dest=\"early_stop_iter\", default=20, type=int,\n",
        "                        help=\"Number of iterations for early stopping. [16]\")\n",
        "\n",
        "    # model settings:\n",
        "    parser.add_argument(\"--nonlinearity_hiddens\", dest='nhidden', default=2, type=int,\n",
        "                        help=\"Hidden size of inner layers of nonlinearity. [1000]\")\n",
        "    parser.add_argument(\"--nonlinearity_dropout\", dest='dropout_p', default=0.0, type=float,\n",
        "                        help=\"The dropout probability in each layer (except scaling layer). [0.8]\")\n",
        "    parser.add_argument(\"--prior\", choices=('logistic', 'Gumbel', 'prior', 'regression'), default='Gumbel',\n",
        "                        help=\"Prior distribution of latent space components. [logistic]\")\n",
        "    parser.add_argument(\"--model_path\", dest='model_path', default=None, type=str,\n",
        "                        help=\"Continue from pretrained model. [None]\")\n",
        "    parser.add_argument(\"--uniform_init_interval\", dest='init_interval', default=1e-2, type=float,\n",
        "                        help=\"The interval of uniform initialization. [0.01]\")\n",
        "\n",
        "    # optimization settings:\n",
        "    parser.add_argument(\"--lr\", default=1e-3, dest='lr', type=float,\n",
        "                        help=\"Learning rate for ADAM optimizer. [0.001]\")\n",
        "    parser.add_argument(\"--beta1\", default=0.9, dest='beta1', type=float,\n",
        "                        help=\"Momentum for ADAM optimizer. [0.9]\")\n",
        "    parser.add_argument(\"--beta2\", default=0.999, dest='beta2', type=float,\n",
        "                        help=\"Beta2 for ADAM optimizer. [0.01]\")\n",
        "    parser.add_argument(\"--eps\", default=1e-8, dest='eps', type=float,\n",
        "                        help=\"Epsilon for ADAM optimizer. [0.0001]\")\n",
        "    parser.add_argument(\"--lambda\", default=0.0, dest='lmbda', type=float,\n",
        "                        help=\"L1 weight decay coefficient. [0.0]\")\n",
        "    parser.add_argument(\"--DataRNGseed\", dest=\"DataRNG_seed\", default=1, type=int,\n",
        "                        help=\"Data random number generator seed. [1]\")\n",
        "    parser.add_argument(\"--ModelRNGseed\", dest=\"ModelRNG_seed\", default=1, type=int,\n",
        "                        help=\"Model random number generator seed. [1]\")\n",
        "    parser.add_argument('-f')\n",
        "    args = parser.parse_args()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "718wvRSXbXdV",
        "outputId": "debafdbd-c24c-4b5b-8168-0635d8bcd0b2"
      },
      "source": [
        "    # ----- run training loop over several epochs & save models for each epoch:\n",
        "    # RNG control\n",
        "    # torch.manual_seed(args.RNG_seed)\n",
        "    # random.seed(args.DataRNG_seed)\n",
        "    # np.random.seed(args.RNG_seed)\n",
        "    torch.set_default_dtype(torch.double)\n",
        "    \n",
        "    # The params files are default in Gen_Source\n",
        "    Sources = Gen_Source(N_sample=7668, seed_gs=args.DataRNG_seed)\n",
        "    Data = Gen_Mixture(Sources, ratio=1)\n",
        "    Data_train, Data_valid = Train_Valid_Split(Data, args.size_train, args.size_valid, args.DataRNG_seed)\n",
        "\n",
        "    train(args, Data_train, Data_valid, Data)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 2558)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ]
}